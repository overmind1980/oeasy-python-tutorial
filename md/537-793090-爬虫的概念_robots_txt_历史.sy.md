---
show: step
version: 1.0
enable_checker: true
---

# 从零开始

## 回忆

- 上次爬了 baidu.com
- 找到了三组链接
- 然后分别遍历
- 百度这种搜索引擎是怎么形成的呢？🤔

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221229-1672298307566)

## 缘起

- 从开始有网页以来
- 人们使用计算机中的浏览器来访问网页

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221222-1671720197358)

- 网页太多太乱
- 能否有个索引呢？

### 雅虎

- 手工收录站点

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221222-1671720386907)

- 站长主动提交网址要求雅虎收录

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221229-1672298663328)

- 但是既然人需要通过计算机访问网页
- 能否用计算机程序批量爬取网页呢？

### 爬虫诞生

- google使用爬虫程序	
	- 爬取网页
	- 存入数据库

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221229-1672298395295)

- 有人来搜索的时候
	- 再到数据库里面进行查询
	- 返回结果
- 逐渐google 代替 yahoo
	- 成为了互联网的入口
- 各个网站非常需要被收录
	- 主动提供
		- sitemap.html

### sitemap.xml

- https://www.58.com/sitemap.xml
	- 可以暴露自身的url的接口
	- http://rkz.58.com/

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20240421-1713705279198)

- 跟下除了sitemap还有
	- robots.txt

### 定义robots.txt

- 后来
	- 有些网站希望成为垂类的入口
	- 要养成用户在本网站或者app搜索的习惯
	- 拒绝google收录
	- 也写在robots.txt中

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221222-1671720285510)

- 甚至还可以拒绝指定的搜索引擎

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221229-1672298778198)

- https://developers.google.cn/search/docs/crawling-indexing/robots/create-robots-txt

### 规则

- ietf制定相应的规则

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221222-1671720314760)

- robots.txt 也开始有了自己的规范

## 总结

- robots.txt是一个爬虫公约
	- 可以对于某些引擎、某些目录
		- 拒绝爬取
		- 或者允许爬取

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20221229-1672299459184)

- 爬取之前需要先观察一下robots.txt
- 可以手动爬取百度指数吗？🤔
- 下次再说👋