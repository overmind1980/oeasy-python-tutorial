---
show: step
version: 1.0
enable_checker: true
---

# 导入 request 包

## 新的开始

- 现在就要学习 python 爬虫了
- 我们从哪里开始呢？
- 首先需要安装一个 http 服务器
- 我们可以从《oeasy 教您玩转 linux》中
	- 找到`nginx`这个实验

### nginx

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630404914608)

- 首先要开启 nginx
  - nginx 是一个静态网页服务器
  - ngin 的意思是 engine x
  - 是一个静态网页的引擎
- /etc/init.d/nginx start
- 完成之后
- 可以在浏览器访问 localhost

### 网页

- 新建一个网页文件 oeasy.html
- 可以自己写
- 也可以 git clone http://gitee.com/overmind1980/oeasypython.git
- 在 /samples/020101/oeasy.html 找到

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630405948096)

- 可以拷贝文件到网页服务器根下
  - 网页服务器根下在哪呢？
    - `whereis nginx`
  - /usr/share/nginx/html/
  - cp ./samples/020101/oeasy.html /usr/share/nginx/html
- 然后就可以在浏览器访问这个文件

### 浏览过程

- 浏览器可以访问到

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630406053309)

- F12 检查元素
- 选择网络 Networks
- 然后刷新

### 刷新

- F5 也可以刷新
- 刷新后会看到网络上的请求和响应

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630406249941)

- 选中 oeasy.html 文件
- 是个 http 的 get 请求和响应的过程
- 请求就是 request
- 响应就是 response

### 请求 Request

- 首先从浏览器发出一个`http get`请求
  - http
    - 超文本传输协议
    - 是网络传输中使用的协议
  - get
    - 是要得到相应文件的方法

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630406366911)

- 这是从火狐浏览器发出的请求
- 火狐浏览器会自动加上一些请求头
  - Accept-Language
    - 请求的语言
  - Host
    - 请求的主机
  - User-Agent
    - 请求的浏览器
- nginx 服务器接收到了请求之后
- 就会进行处理
- 就像搜索引擎会处理的你搜索请求一样
- 只不过这个请求的是一个静态网页
- 服务器就把这个 `网页` 作为 `请求Request `的 `响应Response`
  - 然后这个响应结果就返回回来了

### 响应 Response

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630406600963)

- 服务器根据接收到的东西
- 处理后发回浏览器
- 浏览器会接到响应头
  - Content—Type
    - 接收文件类型
  - Content—Length
    - 内容字节长度
  - Date
    - 接收时间
  - Server
    - 服务器

### 完成

- 这个过程完成了
  - 整个 http get 会得到一个状态码(Status_Code)

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630406753249)

- Get 请求得到了响应
  - 状态码是 200
  - 意思是 OK
- 还有什么别的状态码么？
  - 好像还有 404 之类的状态
- 都是什么意思？
  - 点击状态码后面那个小问号
  - 如果没有网的话就把地址复制粘贴出来

### 状态码

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630406931714)

- 这是火狐对于 HTTP 协议的理解
  - 这理解来自于 [RFC2616](https://www.rfc-editor.org/rfc/inline-errata/rfc2616.html)
  - 也就是 Request for Comments: 2616
  - 当时是 internet society 的一个征求意见的稿子
- 通过这个定义了 http 协议的最初的样子
- 那我们的状态码到底是多少？

### 成功

- 200

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630407043185)

- 200-299 都是成功
- 一般都是成功
- 还能失败吗？

### 失败

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630407083152)

- 比如我们访问一个不存在的资源
- 比如这个 favicon.ico

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630407149757)

- 我们还是再访问 oeasy.html 吧

### 缓存

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630407246277)

- 状态变成了 304
- 什么意思？

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20210831-1630407315587)

- 上次这个浏览器已经得到这个文件了
- 并且已经缓存到了本地硬盘上
- 服务器资源没有修改
- 你就还用上次缓存的吧
- 那如果服务器端修改了呢？

### 修改后访问

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211014-1634188256931)

- 这次浏览器的请求头上面有一个属性
- If-Modified-Since

![图片描述](https://doc.shiyanlou.com/courses/uid1190679-20211015-1634304090189)

- 存折上次缓存时的时间
- 如果服务期没有修改
  - 那就用缓存
- 如果服务器修改了
  - 那就重新下载

## 总结

- 我们安装了 nginx 服务器
- 使用浏览器访问了服务器上的网页
- 网页有各种状态
  - 200 成功
  - 304 未改变
  - 404 找不到
- 可是这个爬虫怎么搞呢？🤣
- 下次再说
