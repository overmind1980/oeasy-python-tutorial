---
show: step
version: 1.0
enable_checker: true
---

# GoPup

## 微博

```
import pandas as pd
import time
from DrissionPage import WebPage

# Define parameters
keyword = '春晚'
page = 10000
begindate = '2025-01-28'
enddate = '2025-01-29'
data = []
for pa in range(1,page+1):
    # Initialize WebPage
    wp = WebPage()
    wp.get(f'https://s.weibo.com/weibo?q={keyword}&typeall=1&suball=1&timescope=custom%3A{begindate}-20%3A{enddate}-14&Refer=g&page={pa}')
    # Scrape the data
    cars = wp.eles('xpath://div[@action-type="feed_list_item"]')

    # Create lists to store the scraped data

    for i in cars:
        nickname = i.ele('xpath://a[@class="name"]').text
        shijian = i.ele('xpath://div[@class="from"]/a').text
        content = i.ele('xpath://p[@node-type="feed_list_content"]').text
        # Append data to list
        data.append([nickname, shijian, content])
    time.sleep(1)
    print(f'爬完了第{pa}页')
# Convert the data into a DataFrame
df = pd.DataFrame(data, columns=['Nickname', 'Time', 'Content'])

# Save the DataFrame to an Excel file
df.to_excel('weibo_scraped_data.xlsx', index=False)

# Print a message when done
print("Data saved to 'weibo_scraped_data.xlsx'")
```

### 抖音

```
from DrissionPage import ChromiumPage
from time import sleep
import datetime
import csv

f = open('data.csv',mode='w',encoding='utf-8-sig',newline='')
csv_writer = csv.DictWriter(f, fieldnames=['昵称','地区','时间','评论内容','点赞数'])
csv_writer.writeheader()

# 创建一个ChromiumPage实例
driver = ChromiumPage()

driver.listen.start('aweme/v1/web/comment/list/')

# 打开抖音视频页面
driver.get('https://www.douyin.com/user/self?modal_id=7362514241460407589&showTab=favorite_collection')

for page in range(50):
    print(f'正在采集第{page+1}页的数据内容')
    driver.scroll.to_bottom()

    resp = driver.listen.wait()

    json_data = resp.response.body
    comments = json_data['comments']
    for index in comments:
        text = index ['text']
        nickname = index['user']['nickname']
        create_time = index['create_time']
        digg_count = index['digg_count']
        date = str(datetime.datetime.fromtimestamp(create_time))
        ip_label = index['ip_label']
        dit = {
            '昵称':nickname,
            '地区':ip_label,
            '时间':date,
            '评论内容':text,
            '点赞数':digg_count
        }

        csv_writer.writerow(dit)
        print(dit)



```