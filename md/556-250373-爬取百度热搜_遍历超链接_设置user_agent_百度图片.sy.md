---
show: step
version: 1.0
enable_checker: true
---

# çˆ¬å–ç™¾åº¦

## å›å¿†

- è¿™æ¬¡çœŸçš„çˆ¬äº†ä¸€ä¸ªç½‘ç«™
  - oeasy.org
- å³é”®æ£€æŸ¥å…ƒç´ 
  - è·å– xpath
- çˆ¬å–ä¹‹åè·å¾—å±æ€§ href çš„å€¼
- ç„¶ååˆ‡ç‰‡å¹¶æ‹¼æ¥ä¸ºç»å¯¹é“¾æ¥åœ°å€
- å¹¶ä¸”æŠŠæ¯ä¸€ä¸ªé“¾æ¥éƒ½çˆ¬äº†ä¸€é
- èƒ½å‡ºå»çˆ¬ä¸ªç™¾åº¦ä¹ˆï¼ŸğŸ¤”

### ç¡®è®¤ä¸Šç½‘

```
firefox https://www.baidu.com &
```

- ä¸€èˆ¬çš„å®éªŒæ¥¼æ³¨å†Œä¼šå‘˜
	- æ˜¯ä¸èƒ½åœ¨è™šæ‹Ÿæœºé‡Œä¸Š baidu ä¹‹ç±»çš„ç½‘ç«™çš„
	- å¯ä»¥åœ¨æœ¬æœºé‡Œä½¿ç”¨ç«ç‹å’Œ python

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240615-1718451563865)

- æƒ³è¦çˆ¬ç™¾åº¦
	- é¦–å…ˆè¦ç¡®è®¤èƒ½ä¸Šç™¾åº¦

### å‡†å¤‡ç¯å¢ƒ

- å¯¼å…¥äº†è¯¥åŒ…
	- ç„¶åå‘é€è¯·æ±‚

```
import requests
from lxml import etree
response = requests.get("http://www.baidu.com")
print(response.content)
```

- è¿”å›ç»“æœæ¯”è¾ƒç®€å•

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20231029-1698541705991)

- è¿™æ˜¯ä¸€ä¸ª
	- å­—èŠ‚åºåˆ—

### ç½‘é¡µå­˜å‚¨

- å°† å­—èŠ‚åºåˆ— è§£ç ä¸º å­—ç¬¦ä¸²

```
import requests
from lxml import etree
response = requests.get("http://www.baidu.com")
print(response.content.decode("utf-8"))
```

- å°†å­—ç¬¦ä¸² è¾“å‡ºé‡å®šå‘ åˆ°b.html

```
python3 b.py > b.html
firefox b.html &
```

### å¯åŠ¨nginx

- å°†æ–‡ä»¶æ‹·è´è¿›
	- nginxæ ¹ç›®å½•

```
sudo cp b.html /usr/share/nginx/html/
sudo service nginx start
firefox http://localhost/b.html &    
```

- å†å¯åŠ¨ç«ç‹æ‰“å¼€ç½‘é¡µ

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240421-1713699972289)

- è¿™å°±æ˜¯æˆ‘ä»¬æŠ“åˆ°çš„ç™¾åº¦é¦–é¡µ	

### æ¯”è¾ƒ

- å°è¯•å’Œç™¾åº¦é¦–é¡µæ¯”è¾ƒ
	- æ˜æ˜¾æ²¡æœ‰ç™¾åº¦çƒ­æœ 

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240615-1718452950840)

- ç™¾åº¦æœ¬èº« ä¾èµ– çˆ¬è™«
	- ä»–å‘ç°äº† æˆ‘ä»¬æ˜¯åŒç±»
	- ç»“æœå°±æŠŠæˆ‘ä»¬ç»™ç¦äº† ğŸ˜°
- é‚£æ€ä¹ˆåŠï¼ŸğŸ˜±

### å‡è£…

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635046905973)

- ç„¶åæŠŠè¿™ä¸ª key-value å¯¹
	- å†™åˆ° header ä¸­
	- å‡è£…æˆ‘ä»¬ æ˜¯ æµè§ˆå™¨

```
import requests
from lxml import etree
headers ={"User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/112.0"}
response = requests.get("http://www.baidu.com", headers=headers)
print(response.content.decode("utf-8"))
```

- æ³¨æ„ headers æ˜¯ä¸€ä¸ªå­—å…¸
  - key-value ä¹‹é—´æœ‰å†’å·
  - key å’Œ value éƒ½æœ‰åŒå¼•å·åŒ…è£¹
  - å†’å·åŒå¼•å·éƒ½æ˜¯åŠè§’çš„
- è¯·æ±‚ä¸­çš„åè®®æ˜¯ https

### ç»“æœ

- å†æ¬¡è¾“å‡ºé‡å®šå‘

```
python3 b.py > b2.html
sudo cp b.html /usr/share/nginx/html/
firefox http://localhost/b.html &    
```

- å¥½åƒå¯ä»¥å¾—åˆ°çƒ­æœåˆ—è¡¨äº†

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240615-1718453296507)


### ç”Ÿæˆ etree

- æŠŠæ­£ç¡®çš„å“åº”æ”¾åˆ°
	- lxml ä¸­è¿›è¡Œè§£æ
	- ç”Ÿæˆä¸€æ£µ etree

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047598112)

- ä½†æ˜¯ å¾—åˆ°çš„ è¿™ä¸€æ£µæ ‘
	- è¦ æ€æ ·æ‰èƒ½ æ‹©åˆ°æƒ³è¦çš„é“¾æ¥ å‘¢?
- éœ€è¦ xpath!!

### æ‰¾ xpath

- æ³¨æ„è¦åœ¨http://localhost/b.htmlä¸ŠæŸ¥æ‰¾xpath
	- å› ä¸ºb.htmlæ˜¯æˆ‘ä»¬å·²ç»çˆ¬åˆ°æ‰‹çš„ç½‘é¡µ

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047760757)

- å³é”® å·¦ä¸Šè§’çš„æ–°é—»
  - æ£€æŸ¥å…ƒç´ 
- å¯ä»¥çœ‹åˆ°ä»–å¯¹åº”ç€ a æ ‡ç­¾
	- åé¢çš„åœ°å›¾ä¹‹ç±»çš„ä¹Ÿå¯¹åº”ç€ a æ ‡ç­¾
- å¦‚ä½•å¾—åˆ° xpath ï¼Ÿ

### å¾—åˆ° xpath

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635047839977)

- å¤åˆ¶ä¹‹å
	- æ€ä¹ˆåŠï¼Ÿ

### å°è¯•

```
import requests
from lxml import etree
headers ={"User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/112.0"}
response = requests.get("https://www.baidu.com", headers=headers)
#print(response.text)
et_html = etree.HTML(response.content)
l_et_a = et_html.xpath("/html/body/div/div[1]/div[@id='s-top-left']/a")
for anchor in l_et_a:
    print(anchor.text)
```

- ä¹Ÿå¯ä»¥ä½¿ç”¨idå±æ€§è°“è¯ç¡®è®¤div

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240615-1718454404368)

- å¦‚æœæˆ‘æƒ³æŠŠé“¾æ¥ä¹Ÿè¾“å‡º
- åº”è¯¥æ€ä¹ˆåŠï¼Ÿ

### è¾“å‡ºè¿æ¥

- å…ˆæŸ¥ä¸€ä¸‹æ–‡æ¡£

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048399340)

```
import requests
from lxml import etree
headers ={"User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/112.0"}
response = requests.get("https://www.baidu.com", headers=headers)
#print(response.text)
et_html = etree.HTML(response.content)
l_et_a = et_html.xpath("/html/body/div/div[1]/div[@id='s-top-left']/a")
for anchor in l_et_a:
    print(anchor.text,end="    ->   ")
    print(anchor.attrib.get("href"))
```

- éå†å®Œæˆ
	- è¿™å¾ˆç®€å•

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240615-1718454502098)

- æˆ‘ä»¬å†çœ‹çœ‹ç™¾åº¦çƒ­æœ

### ç™¾åº¦çƒ­æœ

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635048555965)

- xpath æ˜¯
    - /html/body/div[1]/div[1]/div[5]/div/div/div[3]/ul/li/a/span[2]

### è¿›è¡Œéå†

```
import requests
from lxml import etree
headers ={"User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/112.0"}
response = requests.get("https://www.baidu.com", headers=headers)
#print(response.text)
et_html = etree.HTML(response.content)
l_et_a = et_html.xpath("/html/body/div[1]/div[1]/div[5]/div/div/div[3]/ul/li/a/span[2]")
for anchor in l_et_a:
    print(anchor.text)
```

- ç»“æœ

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240615-1718454603252)

- ä½†æ˜¯æˆ‘å¦‚æœæƒ³è¦åŒæ—¶è¾“å‡ºå…·ä½“é“¾æ¥å‘¢ï¼Ÿ

### é‡æ–°æ„é€ åˆ—è¡¨

- span åœ¨ a é‡Œé¢
	- æ‰€ä»¥æˆ‘ä»¬å…ˆæŠŠæ‰€æœ‰çš„ a çš„åˆ—è¡¨æ‹¿åˆ°
	- ç„¶åå†ä½¿ç”¨ä¸‹è¡¨çš„æ–¹å¼æ‰¾åˆ° span çš„ text

```
import requests
from lxml import etree
headers ={"User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/112.0"}
response = requests.get("https://www.baidu.com", headers=headers)
#print(response.text)
et_html = etree.HTML(response.content)
l_et_a = et_html.xpath("/html/body/div[1]/div[1]/div[5]/div/div/div[3]/ul/li/a")
for anchor in l_et_a:
    et_span = anchor.xpath("./span[2]")[0]
    print(et_span.text,end="   ->   ")
    print(anchor.attrib.get("href"))
```

- ç»“æœ

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240615-1718454823828)

- è¿˜å¯ä»¥éå†æœ€ä¸‹é¢çš„é“¾æ¥å—ï¼Ÿ

### æœ€ä¸‹é¢çš„

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049252958)

- è¿™ä¸ªå¥½åƒæ¯”è¾ƒç®€å•
- æ–‡å­—å’Œé“¾æ¥éƒ½åœ¨ a å…ƒç´ ä¸­

### xpath

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049346923)

- a å…ƒç´ åœ¨ p å…ƒç´ ä¸­
- æ‰€ä»¥æŠŠ p å…ƒç´ çš„ç´¢å¼•å»æ‰
- /html/body/div[1]/div[1]/div[7]/div/p/a

### éå†

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20211024-1635049450518)

```
import requests
from lxml import etree
headers ={"User-Agent": "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/112.0"}
response = requests.get("https://www.baidu.com", headers=headers)
#print(response.text)
et_html = etree.HTML(response.content)
#l_et_a = et_html.xpath("/html/body/div/div[1]/div[3][@id='s-top-left']/a")
#l_et_a = et_html.xpath("/html/body/div/div[1]/div[5]/div/div/div[3]/ul/li/a/span")
l_et_a = et_html.xpath("/html/body/div[1]/div[1]/div[7]/div/p/a")
for anchor in l_et_a:
    print(anchor.text)
    print(anchor.attrib["href"])
```

### çˆ¬å–ç™¾åº¦å›¾ç‰‡

```
# -*- coding:utf8 -*-
import requests
import json
from urllib import parse
import os
import time

class BaiduImageSpider(object):
    def __init__(self):
        self.json_count = 0  # è¯·æ±‚åˆ°çš„jsonæ–‡ä»¶æ•°é‡ï¼ˆä¸€ä¸ªjsonæ–‡ä»¶åŒ…å«30ä¸ªå›¾åƒæ–‡ä»¶ï¼‰
        self.url = 'https://image.baidu.com/search/acjson?tn=resultjson_com&logid=5179920884740494226&ipn=rj&ct' \
                   '=201326592&is=&fp=result&queryWord={' \
                   '}&cl=2&lm=-1&ie=utf-8&oe=utf-8&adpicid=&st=-1&z=&ic=0&hd=&latest=&copyright=&word={' \
                   '}&s=&se=&tab=&width=&height=&face=0&istype=2&qc=&nc=1&fr=&expermode=&nojc=&pn={' \
                   '}&rn=30&gsm=1e&1635054081427= '
        self.directory = r"."  # å­˜å‚¨ç›®å½•  è¿™é‡Œéœ€è¦ä¿®æ”¹ä¸ºè‡ªå·±å¸Œæœ›ä¿å­˜çš„ç›®å½•  {}ä¸è¦ä¸¢
        self.header = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                          'Chrome/95.0.4638.54 Safari/537.36 Edg/95.0.1020.30 '
        }

    # åˆ›å»ºå­˜å‚¨æ–‡ä»¶å¤¹
    def create_directory(self, name):
        self.directory = self.directory.format(name)
        # å¦‚æœç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
        if not os.path.exists(self.directory):
            os.makedirs(self.directory)
        self.directory += r'{}'

    # è·å–å›¾åƒé“¾æ¥
    def get_image_link(self, url):
        list_image_link = []
        strhtml = requests.get(url, headers=self.header)  # Getæ–¹å¼è·å–ç½‘é¡µæ•°æ®
        jsonInfo = json.loads(strhtml.text)
        for index in range(30):
            list_image_link.append(jsonInfo['data'][index]['thumbURL'])
        return list_image_link

    # ä¸‹è½½å›¾ç‰‡
    def save_image(self, img_link, filename):
        res = requests.get(img_link, headers=self.header)
        if res.status_code == 404:
            print(f"å›¾ç‰‡{img_link}ä¸‹è½½å‡ºé”™------->")
        with open(filename, "wb") as f:
            f.write(res.content)
            print("å­˜å‚¨è·¯å¾„ï¼š" + filename)

    # å…¥å£å‡½æ•°
    def run(self):
        searchName = input("æŸ¥è¯¢å†…å®¹ï¼š")
        searchName_parse = parse.quote(searchName)  # ç¼–ç 

        self.create_directory(searchName)

        pic_number = 0  # å›¾åƒæ•°é‡
        for index in range(self.json_count):
            pn = (index+1)*30
            request_url = self.url.format(searchName_parse, searchName_parse, str(pn))
            list_image_link = self.get_image_link(request_url)
            for link in list_image_link:
                pic_number += 1
                self.save_image(link, self.directory.format(str(pic_number)+'.jpg'))
                time.sleep(0.2)  # ä¼‘çœ 0.2ç§’ï¼Œé˜²æ­¢å°ip
        print(searchName+"----å›¾åƒä¸‹è½½å®Œæˆ--------->")

if __name__ == '__main__':
    spider = BaiduImageSpider()
    spider.json_count = 10   # å®šä¹‰ä¸‹è½½10ç»„å›¾åƒï¼Œä¹Ÿå°±æ˜¯ä¸‰ç™¾å¼ 
    spider.run()
```

### å°†ç™¾åº¦å½“ä½œæ•°æ®åº“æ¥ç”¨

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240524-1716513949346)

- æŸ¥è¯¢ åª’ä½“ 
	- æ¾æ¹ƒæ–°é—» ä¸­ å‡ºç° riscv çš„æƒ…å†µ

### å°†ç™¾åº¦ å½“ä½œæ•°æ®åº“

![å›¾ç‰‡æè¿°](https://doc.shiyanlou.com/courses/uid1190679-20240524-1716514003090)

- æŸ¥è¯¢ æå‡»å‘¨è¯„ è´¦æˆ·
	- å‘è¡¨è¿‡çš„ 
	- å…³äºæŸ”æœ¯çš„ æ–‡ç« 

### æ€»ç»“

- è¿™æ¬¡çˆ¬äº† baidu.com
	- æ‰¾åˆ°äº†ä¸‰ç»„é“¾æ¥
	- ç„¶ååˆ†åˆ«éå†
- ä½†æ˜¯ headers ç”Ÿæˆçš„æ–¹æ³•æœ‰ç‚¹éº»çƒ¦
- æœ‰æ›´å¿«çš„ç”Ÿæˆheadersçš„æ–¹æ³•å—ï¼Ÿ
- ä¸‹æ¬¡å†è¯´
